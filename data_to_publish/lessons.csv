lesson_id,course_id,lesson_num,Name,Web URL,topic_tags,Skills,Topic,Tags
az-01,azure-llmops-workshop,1,Lab 01: Introduction to LLMs and Azure AI Services,https://microsoft.github.io/llmops-workshop/labs/lesson_01/lab01.html,"lifecycle,intro",Azure AI Studio navigation; Azure OpenAI model deployment; Open-source LLM deployment (Azure); Prompt Playground experimentation; Content Safety configuration; Prompt Flow creation,Foundations & Lifecycle; Deployment & Serving; Safety & Responsible AI; Orchestration & Workflows,Azure; Azure AI Studio; Azure OpenAI; Llama 2; Prompt Flow; Content Safety; Hands-on; Beginner
az-02,azure-llmops-workshop,2,Lab 02: Building LLM Orchestration Flows,https://microsoft.github.io/llmops-workshop/labs/lesson_02/lab02.html,"orchestration,prompt-management",Prompt Flow orchestration; Classification flow build (Prompt Flow); RAG flow build (Prompt Flow + Azure AI Search); Search index setup (Azure AI Search); Flow runtime & connections (Azure OpenAI),Orchestration & Workflows; Retrieval-Augmented Generation (RAG); Prompting & Prompt Management,Azure; Azure AI Studio; Prompt Flow; Azure AI Search; RAG; Classification; Hands-on
az-03,azure-llmops-workshop,3,Lab 03: Evaluating and Deploying LLMs,https://microsoft.github.io/llmops-workshop/labs/lesson_03/lab03.html,"evaluation,deployment",RAG flow evaluation (Prompt Flow); Groundedness evaluation flow; Evaluation dataset preparation; Managed endpoint deployment; Post-deploy validation,Evaluation & Testing; Deployment & Serving; Retrieval-Augmented Generation (RAG),Azure; Azure AI Studio; Prompt Flow; Evaluation; Groundedness; Managed endpoint; RAG; Hands-on
az-04,azure-llmops-workshop,4,Lab 04: Monitoring and Responsible AI,https://microsoft.github.io/llmops-workshop/labs/lesson_04/lab04.html,"monitoring,observability,content-safety",LLM monitoring enablement; Monitoring metrics preparation; Content Safety tool integration; Conditional safety routing (Prompt Flow); Operational debugging,Monitoring & Observability; Safety & Responsible AI,Azure; Monitoring; Prompt Flow; Content Safety; Responsible AI; Hands-on
az-05,azure-llmops-workshop,5,Lab 05: Automating Everything (CI/CD),https://microsoft.github.io/llmops-workshop/labs/lesson_05/lab05.html,"automation,ci-cd",GitHub Actions CI/CD setup; Automated PR evaluation pipeline; Golden dataset evaluation gate; CI build + CD deploy (Prompt Flow); Release workflow (branching/versioning),CI/CD & Release Automation; Evaluation & Testing; Deployment & Serving,Azure; GitHub Actions; CI/CD; Prompt Flow; LLMOps Accelerator; Golden dataset; Hands-on
az-06,azure-llmops-workshop,6,Extra: Benchmarking Azure OpenAI Models,https://microsoft.github.io/llmops-workshop/labs/performance/docs/AOAI_BENCH_TOOL.html,"performance,evaluation",Model benchmarking; Quality/cost tradeoff analysis; Model selection workflow,Evaluation & Testing; Performance & Load Testing,Azure OpenAI; Benchmarking; Model selection; Evaluation; Performance
az-07,azure-llmops-workshop,7,Extra: Performance Evaluation / Load Testing,https://microsoft.github.io/llmops-workshop/labs/performance/docs/PERFTEST_CONCEPTS.html,"performance,load-testing",Load testing; Latency/throughput measurement; Scaling analysis,Performance & Load Testing; Deployment & Serving,Load testing; Performance; Latency; Throughput; Scaling; Azure
gcp-01,gcp-llmops-overview,1,What is LLMOps (overview),https://cloud.google.com/discover/what-is-llmops,"lifecycle,definition",LLMOps lifecycle mapping; LLMOps best-practice framing,Foundations & Lifecycle,Google Cloud; Conceptual; LLMOps definition; Lifecycle
gcp-02,gcp-llmops-overview,2,Vertex AI Model Registry (lifecycle management),https://docs.cloud.google.com/vertex-ai/docs/model-registry/introduction,"model-registry,versioning",Vertex AI Model Registry usage; Model versioning & lineage; Model lifecycle promotion,Model Registry & Versioning; Foundations & Lifecycle,Google Cloud; Vertex AI; Model Registry; Versioning
gcp-03,gcp-llmops-overview,3,Vertex AI Pipelines (automation),https://docs.cloud.google.com/vertex-ai/docs/pipelines/introduction,"pipelines,automation",Vertex AI Pipelines orchestration; Pipeline automation; Pipeline parameterization,Orchestration & Workflows; CI/CD & Release Automation,Google Cloud; Vertex AI Pipelines; Automation; Pipelines
gcp-04,gcp-llmops-overview,4,Vertex AI Model Evaluation (overview),https://docs.cloud.google.com/vertex-ai/docs/evaluation/introduction,evaluation,Vertex AI model evaluation; Metric selection; Model comparison,Evaluation & Testing,Google Cloud; Vertex AI; Evaluation; Metrics
gcp-05,gcp-llmops-overview,5,Vertex AI Model Monitoring (overview),https://docs.cloud.google.com/vertex-ai/docs/model-monitoring/overview,monitoring,Vertex AI model monitoring; Drift detection; Alerting configuration,Monitoring & Observability,Google Cloud; Vertex AI; Monitoring; Drift; Alerts
awsw-00,aws-llmops-workshop,1,Lab 0: Register base model (notebook),https://github.com/aws-samples/llmops-workshop/blob/main/lab0-register-base-model.ipynb,"model-registry,lifecycle",SageMaker Model Registry registration; Model package governance; Lifecycle state management,Model Registry & Versioning; Foundations & Lifecycle,AWS; Amazon SageMaker; Model Registry; Workshop; Notebook
awsw-01,aws-llmops-workshop,2,Lab 1: Finetune Llama2 with QLoRA (notebook),https://github.com/aws-samples/llmops-workshop/blob/main/lab1-sagemaker-finetune-llama2-qlora.ipynb,"post-training,qlora,peft",SageMaker fine-tuning job; QLoRA fine-tuning; Model deployment (SageMaker Hosting),Fine-tuning & Post-training; Deployment & Serving,AWS; Amazon SageMaker; Llama 2; QLoRA; Fine-tuning; Notebook
awsw-02,aws-llmops-workshop,3,Lab 2: Build SageMaker pipeline for LLM (notebook),https://github.com/aws-samples/llmops-workshop/blob/main/lab2-sagemaker-pipeline-llm.ipynb,"pipelines,automation",SageMaker Pipelines workflow; Training pipeline automation; CI/CD integration (CodePipeline),Orchestration & Workflows; CI/CD & Release Automation; Deployment & Serving,AWS; SageMaker Pipelines; CodePipeline; Automation; Notebook
awsw-03,aws-llmops-workshop,4,Lab 3: Foundation model monitoring (folder),https://github.com/aws-samples/llmops-workshop/tree/main/lab3-sagemaker-fm-monitoring,"monitoring,observability",SageMaker Model Monitor configuration; Monitoring schedule setup; BYOC monitoring,Monitoring & Observability,AWS; SageMaker Model Monitor; LLM Monitoring; BYOC; Observability
awsw-04,aws-llmops-workshop,5,Lab 4: JumpStart embeddings (notebook),https://github.com/aws-samples/llmops-workshop/blob/main/lab4-sagemaker-jumpstart-embeddings.ipynb,"embeddings,retrieval",JumpStart embeddings deployment; Embedding generation; Vector store setup (OpenSearch),Retrieval-Augmented Generation (RAG); Deployment & Serving,AWS; SageMaker JumpStart; Embeddings; OpenSearch Serverless; RAG; Notebook
awsw-05,aws-llmops-workshop,6,Lab 5: Knowledge base chatbot (notebook),https://github.com/aws-samples/llmops-workshop/blob/main/lab5-knowledge-base-chatbot.ipynb,"rag,app-integration",Document ingestion for RAG; LangChain RAG application; Vector DB querying (OpenSearch); Streamlit chatbot UI,Retrieval-Augmented Generation (RAG); Orchestration & Workflows; Deployment & Serving,AWS; OpenSearch Serverless; LangChain; Streamlit; RAG; Chatbot; Notebook
awsb-01,aws-llmops-blog-series,1,LLMOps solution overview (Part I),https://aws.amazon.com/blogs/gametech/operationalize-generative-ai-applications-on-aws-part-i-overview-of-llmops-solution/,"architecture,lifecycle",LLMOps reference architecture review; Service-to-lifecycle mapping,Foundations & Lifecycle; CI/CD & Release Automation; Deployment & Serving,AWS; Reference architecture; Blog; LLMOps solution
awsb-02,aws-llmops-blog-series,2,SageMaker Clarify: Get started with model evaluations,https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-foundation-model-evaluate-get-started.html,evaluation,Foundation model evaluation (Clarify); Automatic vs human eval workflows; fmeval-based evaluation,Evaluation & Testing; Safety & Responsible AI,AWS; SageMaker Clarify; fmeval; Evaluation; Responsible AI
awsb-03,aws-llmops-blog-series,3,SageMaker Model Monitor (examples index),https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/index.html,monitoring,Model Monitor setup; LLM monitoring (BYOC); Monitoring schedule operations,Monitoring & Observability,AWS; SageMaker Model Monitor; LLM Monitoring; BYOC; Monitoring schedule
awsb-04,aws-llmops-blog-series,4,SageMaker Clarify + fmeval (re:Post article),https://repost.aws/articles/ARXsxgLFa7R-uw8TgUo1fDJg/accelerate-foundation-model-evaluation-with-amazon-sagemaker-clarify-and-fmeval,"evaluation,tooling",Clarify + fmeval evaluation workflow; Evaluation reporting,Evaluation & Testing,AWS; SageMaker Clarify; fmeval; re:Post; Evaluation
db-01,databricks-llmops,1,Databricks LLMOps overview,https://www.databricks.com/glossary/llmops,"definition,lifecycle",LLMOps lifecycle framing (Databricks),Foundations & Lifecycle,Databricks; Glossary; Conceptual
db-02,databricks-llmops,2,Evaluate and monitor AI agents (MLflow for GenAI),https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/,"evaluation,monitoring,agents",Agent evaluation (MLflow); Agent monitoring; Trace logging,Evaluation & Testing; Monitoring & Observability; Orchestration & Workflows,Databricks; MLflow for GenAI; Agents; Evaluation; Monitoring
db-03,databricks-llmops,3,Implement LLMOps with Azure Databricks (lab),https://microsoftlearning.github.io/mslearn-databricks/Instructions/Exercises/AI-07-LLMOps.html,"deployment,tracking,governance",LLMOps implementation (Azure Databricks); Experiment/prompt tracking (MLflow); GenAI app deployment; Governance controls,Deployment & Serving; Model Registry & Versioning; Governance & Compliance,Azure Databricks; Databricks; MLflow; Lab; Governance
db-04,databricks-llmops,4,Microsoft Learn module: Implement LLMOps with Azure Databricks,https://learn.microsoft.com/en-us/training/modules/implement-llmops-azure-databricks/,"lifecycle,deployment",LLMOps implementation patterns (Azure Databricks); Operational lifecycle setup,Foundations & Lifecycle; Deployment & Serving,Microsoft Learn; Azure Databricks; Training module
ibm-01,ibm-llmops,1,IBM: What are Large Language Model Operations (LLMOps)?,https://www.ibm.com/think/topics/llmops,"definition,lifecycle",LLMOps definition & lifecycle framing; LLMOps vs MLOps comparison,Foundations & Lifecycle,IBM; Conceptual; LLMOps overview
ibm-02,ibm-llmops,2,IBM watsonx guide (LLMOps framing),https://ibm.github.io/MLOps/watsonx/watsonx/watsonx.pdf,"governance,lifecycle",watsonx LLMOps workflow framing; Enterprise governance planning,Foundations & Lifecycle; Governance & Compliance,IBM; watsonx; Governance; Enterprise
ibm-03,ibm-llmops,3,IBM community: Build an agentic LLMOps stack with watsonx,https://community.ibm.com/community/user/blogs/patrick-meyer/2025/09/18/build-an-agentic-llmops-stack-with-ibm-watsonx,"agents,orchestration,governance",Agentic workflow design; Agent/tool orchestration; Governance for agentic systems,Orchestration & Workflows; Governance & Compliance,IBM; Agentic; Orchestration; Community article
ibm-04,ibm-llmops,4,IBM MLOps guide (governance/risk toolkit mentions),https://ibm.github.io/MLOps/pdf/mlops-guide.pdf,"governance,risk",AI governance & risk controls; Compliance/audit processes,Governance & Compliance; Safety & Responsible AI,IBM; Governance; Risk; PDF
oci-01,oracle-llmops,1,Oracle LLMOps overview,https://www.oracle.com/artificial-intelligence/llmops/,"definition,monitoring",LLMOps overview (Oracle); OCI service mapping for LLMOps,Foundations & Lifecycle,Oracle; OCI; Conceptual
oci-02,oracle-llmops,2,Deploy LLM on OCI Data Science using BYOC (vLLM),https://github.com/oracle-samples/oci-data-science-ai-samples/blob/main/LLM/deploy-llm-byoc.md,"deployment,serving,open-models",BYOC serving deployment (OCI Data Science); Containerized LLM serving (vLLM),Deployment & Serving,Oracle; OCI Data Science; BYOC; vLLM; Serving
oci-03,oracle-llmops,3,OCI Observability & Monitoring platform (PDF guide),https://www.oracle.com/a/otn/docs/oracle_distributed_cloud_systems_oci_observability_and_management_v.0.2.pdf,"observability,monitoring",Observability dashboarding; Logs/metrics/traces analysis; Alerting configuration,Monitoring & Observability,Oracle; OCI Observability; Monitoring; PDF
oci-04,oracle-llmops,4,Monitoring OCI DevOps performance (Observability & Mgmt),https://www.ateam-oracle.com/monitor-oci-devops-performance-observability-and-management,"ci-cd,monitoring",CI/CD observability; DevOps pipeline performance monitoring,CI/CD & Release Automation; Monitoring & Observability,Oracle; OCI DevOps; CI/CD; Observability
hf-01,hf-open-llmops-primitives,1,TRL (Transformer Reinforcement Learning) docs index,https://huggingface.co/docs/trl/index,"post-training,rlhf,dpo",RLHF training (TRL); DPO preference optimization; Transformers + TRL integration,Fine-tuning & Post-training,Hugging Face; TRL; RLHF; DPO; Training
hf-02,hf-open-llmops-primitives,2,PEFT docs index,https://huggingface.co/docs/peft/index,"peft,lora",PEFT fine-tuning; LoRA adapter training; Adapter merge/export,Fine-tuning & Post-training,Hugging Face; PEFT; LoRA; Fine-tuning
hf-03,hf-open-llmops-primitives,3,Accelerate docs index,https://huggingface.co/docs/accelerate/index,distributed-training,Distributed training (Accelerate); Multi-GPU launch; Mixed-precision tuning,Fine-tuning & Post-training; Orchestration & Workflows,Hugging Face; Accelerate; Distributed training; Performance
hf-04,hf-open-llmops-primitives,4,Transformers pipeline tutorial (inference primitive),https://github.com/huggingface/transformers/blob/main/docs/source/en/pipeline_tutorial.md,"inference,ecosystem-primitives",Transformers pipelines inference; Task selection (pipeline API); Device placement (CPU/GPU),Deployment & Serving,Hugging Face; Transformers; Pipelines; Inference
el-01,eleutherai-eval,1,lm-evaluation-harness repository (core),https://github.com/EleutherAI/lm-evaluation-harness,"evaluation,reproducibility",Benchmark execution (lm-eval-harness); Reproducible evaluation runs,Evaluation & Testing,EleutherAI; lm-evaluation-harness; Benchmarking; Open-source
el-02,eleutherai-eval,2,lm-evaluation-harness: Task guide (docs),https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs,"tasks,prompt-templates",Task configuration; Prompt template authoring; Custom metric configuration,Evaluation & Testing; Prompting & Prompt Management,EleutherAI; Tasks; Prompt templates; Evaluation
el-03,eleutherai-eval,3,lm-evaluation-harness: Models/backends config,https://github.com/EleutherAI/lm-evaluation-harness/tree/main/lm_eval/models,"backends,serving-integration",Model backend configuration; Serving backend integration for evals,Evaluation & Testing; Deployment & Serving,EleutherAI; Backends; Serving integration; Evaluation
el-04,eleutherai-eval,4,lm-evaluation-harness: CLI usage / getting started,https://github.com/EleutherAI/lm-evaluation-harness#usage,"tooling,workflows",CLI-driven evaluation workflow; Batching/performance tuning for evals,Evaluation & Testing; Orchestration & Workflows,EleutherAI; CLI; Automation; Evaluation
vllm-01,vllm-serving,1,vLLM docs (landing),https://docs.vllm.ai/,"serving,inference",vLLM installation & setup; Efficient inference serving,Deployment & Serving; Performance & Load Testing,vLLM; Serving; Inference; Open-source; Performance
vllm-02,vllm-serving,2,OpenAI-compatible server (docs),https://docs.vllm.ai/en/v0.13.0/serving/openai_compatible_server/,"openai-compatible-api,serving",OpenAI-compatible server (vLLM); API endpoint configuration,Deployment & Serving,vLLM; OpenAI-compatible API; Server; Serving
vllm-03,vllm-serving,3,vLLM GitHub repository,https://github.com/vllm-project/vllm,"implementation,deploy",Source build & dependency management; Upstream contribution workflow,Deployment & Serving,vLLM; GitHub; Build; Open-source
vllm-04,vllm-serving,4,vLLM: serving guides index,https://docs.vllm.ai/en/latest/serving/offline_inference/,"deployment,ops",Production deployment patterns (vLLM); Operational serving configuration,Deployment & Serving; Monitoring & Observability,vLLM; Deployment; Ops; Serving guides
phx-01,phoenix-observability,1,Phoenix tracing overview (LLM traces),https://arize.com/docs/phoenix/tracing/llm-traces,"tracing,observability",LLM tracing concepts; Trace analysis for debugging,Monitoring & Observability,Phoenix; Tracing; Observability; Debugging
phx-02,phoenix-observability,2,Phoenix tracing: How-to (manual),https://arize.com/docs/phoenix/tracing/how-to-tracing,"tracing,instrumentation",Tracing instrumentation; Trace export to Phoenix,Monitoring & Observability,Phoenix; Instrumentation; Tracing; How-to
phx-03,phoenix-observability,3,Phoenix tracing tutorial,https://arize.com/docs/phoenix/tracing/tutorial,"debugging,workflow",Tracing tutorial workflow; End-to-end run debugging,Monitoring & Observability; Orchestration & Workflows,Phoenix; Tutorial; Tracing; Hands-on
phx-04,phoenix-observability,4,Phoenix docs section index (tracing/evals/datasets),https://docs.arize.com/phoenix/tracing/how-to-tracing/trace-,"observability,evaluation",Observability + eval workflow navigation; Dataset/eval operations,Monitoring & Observability; Evaluation & Testing,Phoenix; Evals; Datasets; Observability
mlf-01,mlflow-genai,1,MLflow: Evaluate prompts (Prompt Registry),https://mlflow.org/docs/latest/genai/prompt-registry/evaluate-prompts/,"prompt-management,evaluation",Prompt Registry usage; Prompt versioning; Prompt evaluation,Prompting & Prompt Management; Evaluation & Testing; Model Registry & Versioning,MLflow; Prompt Registry; Prompt management; Evaluation; Versioning
mlf-02,mlflow-genai,2,Databricks docs: Evaluate & monitor AI agents (MLflow GenAI),https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/,"evaluation,monitoring",Agent evaluation (MLflow); Agent monitoring; Trace logging,Evaluation & Testing; Monitoring & Observability; Orchestration & Workflows,Databricks; MLflow; Agents; Evaluation; Monitoring
mlf-03,mlflow-genai,3,Azure Databricks: Evaluate & monitor AI agents,https://learn.microsoft.com/en-us/azure/databricks/mlflow3/genai/eval-monitor/,"evaluation,monitoring",Agent evaluation (Azure Databricks); MLflow tracking; Agent monitoring,Evaluation & Testing; Monitoring & Observability; Orchestration & Workflows,Azure Databricks; MLflow; Agents; Evaluation; Monitoring
mlf-04,mlflow-genai,4,Databricks LLMOps glossary (context),https://www.databricks.com/glossary/llmops,"lifecycle,tracking",LLMOps tracking concepts; Lifecycle framing (Databricks),Foundations & Lifecycle; Model Registry & Versioning,Databricks; Tracking; Lifecycle; Glossary
orlhf-01,openrlhf-posttraining,1,OpenRLHF repository (overview),https://github.com/OpenRLHF/OpenRLHF,"rlhf,post-training",RLHF stack setup (OpenRLHF); Post-training workflow overview,Fine-tuning & Post-training,OpenRLHF; RLHF; Post-training; Open-source
orlhf-02,openrlhf-posttraining,2,OpenRLHF README (architecture + quickstart),https://github.com/OpenRLHF/OpenRLHF#readme,"scaling,serving-integration",PPO/DPO workflow execution; Distributed RLHF training; Serving integration in training loops,Fine-tuning & Post-training; Deployment & Serving,OpenRLHF; PPO; DPO; Distributed training; Serving integration
orlhf-03,openrlhf-posttraining,3,OpenRLHF issues/discussions (community practices),https://github.com/OpenRLHF/OpenRLHF/issues,"ops,community",Operational troubleshooting (RLHF); Community practice review,Operations & Maintenance,OpenRLHF; Troubleshooting; Community; Issues
orlhf-04,openrlhf-posttraining,4,OpenRLHF releases (versioning),https://github.com/OpenRLHF/OpenRLHF/releases,"versioning,maintenance",Release/version tracking; Upgrade planning,Model Registry & Versioning; Operations & Maintenance,OpenRLHF; Releases; Versioning; Maintenance
lc-01,langchain-observability,1,LangChain observability (docs landing),https://docs.langchain.com/oss/python/langchain/observability,"observability,tracing",Tracing enablement (LangChain); Run inspection & debugging,Monitoring & Observability,LangChain; Observability; Tracing; Debugging
lc-02,langchain-observability,2,LangChain observability: tracing setup,https://docs.langchain.com/oss/python/langchain/observability#tracing,"tracing,setup",Tracing setup; Callback instrumentation,Monitoring & Observability,LangChain; Tracing setup; Instrumentation; Callbacks
lc-03,langchain-observability,3,LangChain observability: evaluation hooks,https://docs.langchain.com/oss/python/langchain/observability#evaluation,"evaluation,monitoring",Evaluation hooks; Quality signal capture,Evaluation & Testing; Monitoring & Observability,LangChain; Evaluation; Monitoring; Quality signals
lc-04,langchain-observability,4,LangChain observability: debugging patterns,https://docs.langchain.com/oss/python/langchain/observability#debugging,"debugging,ops",Debugging patterns; Operational troubleshooting,Monitoring & Observability; Operations & Maintenance,LangChain; Debugging; Ops; Troubleshooting
li-01,llamaindex-observability,1,LlamaIndex observability guide (landing),https://developers.llamaindex.ai/python/framework/module_guides/observability/,"observability,tracing",Observability enablement (LlamaIndex); Telemetry inspection,Monitoring & Observability,LlamaIndex; Observability; Tracing; Telemetry
li-02,llamaindex-observability,2,LlamaIndex: OpenTelemetry / tracing integration,https://developers.llamaindex.ai/python/framework/module_guides/observability/#opentelemetry,"tracing,otel",OpenTelemetry integration; Trace export configuration,Monitoring & Observability,LlamaIndex; OpenTelemetry; Tracing; Integration
li-03,llamaindex-observability,3,LlamaIndex: Phoenix integration,https://developers.llamaindex.ai/python/framework/module_guides/observability/#phoenix-arize,"observability,phoenix",Phoenix integration; RAG trace debugging,Monitoring & Observability,LlamaIndex; Phoenix; Tracing; RAG debugging
li-04,llamaindex-observability,4,LlamaIndex: evaluation/monitoring integrations,https://developers.llamaindex.ai/python/framework/module_guides/observability/#evaluation,"evaluation,monitoring",Evaluation/monitoring integrations; RAG quality checks,Evaluation & Testing; Monitoring & Observability,LlamaIndex; Evaluation; Monitoring; Integrations; RAG
oc-01,openclaw-getting-started,1,Install OpenClaw + prerequisites,https://docs.openclaw.ai/start/getting-started,"lifecycle,deployment",Install tooling; verify environment,Lifecycle; Deployment,setup; install
oc-02,openclaw-getting-started,2,Onboard configuration (auth + gateway + channels),https://docs.openclaw.ai/start/getting-started,"automation,security,deployment",Run onboarding wizard; configure auth; initialize gateway settings,Automation; Security/compliance; Deployment,onboarding; auth; config
oc-03,openclaw-getting-started,3,Run Gateway as a service (daemon),https://docs.openclaw.ai/start/getting-started,"deployment,operations",Install/manage daemon; start/stop service,Deployment; Operations,service; daemon
oc-04,openclaw-getting-started,4,Check Gateway health + troubleshoot (status/foreground),https://docs.openclaw.ai/start/getting-started,"monitoring,observability",Health checks; basic debugging via foreground logs,Monitoring & Evaluation; Observability,status; troubleshooting
oc-05,openclaw-getting-started,5,Access Control UI + send a test message (smoke test),https://docs.openclaw.ai/start/getting-started,"lifecycle,validation",Open dashboard; run CLI smoke test,Lifecycle; Monitoring & Evaluation,smoke-test; dashboard; cli
